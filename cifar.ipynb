{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Images on CIFAR-10\n",
    "\n",
    "* Author: Jay Huang\n",
    "* E-mail: askjayhuang at gmail dot com\n",
    "* GitHub: https://github.com/jayhuang1\n",
    "* Created: 2018-01-01\n",
    "\n",
    "This workshop predicts a class of an image using image recognition on the CIFAR-10 dataset. The consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class. The training set contains 50,000 images while the test set contains 10,000 images. The 10 object classes are: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck.\n",
    "\n",
    "Classification machine learning algorithms such as Random Forest and  Naive Bayes will first be used. We will then use convolutional neural networks to see if we can get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion\n",
    "\n",
    "The CIFAR-10 data was ingested from the Keras dataset module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global constants that describe the dataset are set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "IMG_DIM = 32\n",
    "LABEL_NAMES = ['airplane', 'automobile', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our classification implementation, the fit function in scikit-learn only accepts 2D arrays. Therefore, we need to reshape our data we downloaded from Keras from a 4D array into a 2D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny, nz = X_train.shape\n",
    "X_train_cl = X_train.reshape((nsamples, nx * ny * nz))\n",
    "nsamples, nx, ny, nz = X_test.shape\n",
    "X_test_cl = X_test.reshape((nsamples, nx * ny * nz))\n",
    "y_train_cl = y_train\n",
    "y_test_cl = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our neural networks implementation, the input data is standardized and the label data needs to be converted into a category matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "X_train_nn = X_train.astype('float32')\n",
    "X_test_nn = X_test.astype('float32')\n",
    "X_train_nn /= 255\n",
    "X_test_nn /= 255\n",
    "y_train_nn = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test_nn = keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Let's first predict the class of an image by using conventional classification algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "def fit_model():\n",
    "    # Train model\n",
    "    start = time.time()\n",
    "    model.fit(X_train_cl, y_train_cl)\n",
    "    duration = time.time() - start\n",
    "\n",
    "    print(\"{:25} fit in: {:0.2f} seconds\".format(model.__class__.__name__, duration))\n",
    "\n",
    "    # Test model\n",
    "    y_pred = model.predict(X_test_cl)\n",
    "\n",
    "    print(classification_report(y_test_cl, y_pred, target_names=LABEL_NAMES))\n",
    "    print('Mean accuracy:', model.score(X_test_cl, y_test_cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron                fit in: 14.89 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   airplane       0.49      0.19      0.27      1000\n",
      " automobile       0.95      0.02      0.04      1000\n",
      "       bird       0.28      0.09      0.14      1000\n",
      "        cat       0.18      0.46      0.26      1000\n",
      "       deer       0.22      0.45      0.30      1000\n",
      "        dog       0.31      0.06      0.10      1000\n",
      "       frog       0.38      0.34      0.36      1000\n",
      "      horse       0.52      0.20      0.29      1000\n",
      "       ship       0.53      0.01      0.02      1000\n",
      "      truck       0.24      0.77      0.36      1000\n",
      "\n",
      "avg / total       0.41      0.26      0.21     10000\n",
      "\n",
      "Mean accuracy: 0.2586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier    fit in: 26.73 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   airplane       0.38      0.54      0.45      1000\n",
      " automobile       0.36      0.43      0.39      1000\n",
      "       bird       0.24      0.31      0.27      1000\n",
      "        cat       0.25      0.25      0.25      1000\n",
      "       deer       0.30      0.29      0.30      1000\n",
      "        dog       0.34      0.29      0.31      1000\n",
      "       frog       0.41      0.35      0.38      1000\n",
      "      horse       0.43      0.31      0.36      1000\n",
      "       ship       0.52      0.46      0.49      1000\n",
      "      truck       0.44      0.36      0.39      1000\n",
      "\n",
      "avg / total       0.37      0.36      0.36     10000\n",
      "\n",
      "Mean accuracy: 0.3588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB                fit in: 2.82 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   airplane       0.27      0.49      0.35      1000\n",
      " automobile       0.41      0.17      0.24      1000\n",
      "       bird       0.19      0.08      0.12      1000\n",
      "        cat       0.25      0.08      0.12      1000\n",
      "       deer       0.24      0.42      0.30      1000\n",
      "        dog       0.31      0.26      0.29      1000\n",
      "       frog       0.25      0.47      0.33      1000\n",
      "      horse       0.42      0.13      0.20      1000\n",
      "       ship       0.39      0.47      0.42      1000\n",
      "      truck       0.38      0.41      0.39      1000\n",
      "\n",
      "avg / total       0.31      0.30      0.28     10000\n",
      "\n",
      "Mean accuracy: 0.2976\n",
      "MultinomialNB             fit in: 1.14 seconds\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   airplane       0.43      0.38      0.40      1000\n",
      " automobile       0.33      0.18      0.23      1000\n",
      "       bird       0.31      0.14      0.20      1000\n",
      "        cat       0.26      0.10      0.14      1000\n",
      "       deer       0.28      0.18      0.22      1000\n",
      "        dog       0.22      0.43      0.29      1000\n",
      "       frog       0.33      0.33      0.33      1000\n",
      "      horse       0.23      0.26      0.24      1000\n",
      "       ship       0.34      0.44      0.38      1000\n",
      "      truck       0.29      0.51      0.37      1000\n",
      "\n",
      "avg / total       0.30      0.29      0.28     10000\n",
      "\n",
      "Mean accuracy: 0.2933\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "models = (Perceptron(),\n",
    "          RandomForestClassifier(),\n",
    "          GaussianNB(),\n",
    "          MultinomialNB(),\n",
    "         )\n",
    "\n",
    "for model in models:\n",
    "    fit_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then build a basic neural network model using Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "PATIENCE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 32, 30, 30)        9248      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 32, 30, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 32, 15, 15)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32, 15, 15)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 64, 15, 15)        18496     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 64, 15, 15)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 64, 13, 13)        36928     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 64, 13, 13)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 64, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 387s 8ms/step - loss: 2.0900 - acc: 0.2193 - val_loss: 1.7854 - val_acc: 0.3654\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 1.7281 - acc: 0.3647 - val_loss: 1.5845 - val_acc: 0.4242\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 383s 8ms/step - loss: 1.5484 - acc: 0.4376 - val_loss: 1.3989 - val_acc: 0.4945\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 384s 8ms/step - loss: 1.4253 - acc: 0.4859 - val_loss: 1.5768 - val_acc: 0.4551\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 384s 8ms/step - loss: 1.3441 - acc: 0.5172 - val_loss: 1.2618 - val_acc: 0.5512\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 383s 8ms/step - loss: 1.2791 - acc: 0.5415 - val_loss: 1.1639 - val_acc: 0.5934\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 382s 8ms/step - loss: 1.2227 - acc: 0.5650 - val_loss: 1.1858 - val_acc: 0.5797\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 1.1714 - acc: 0.5835 - val_loss: 1.0726 - val_acc: 0.6225\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 1.1184 - acc: 0.6042 - val_loss: 1.0544 - val_acc: 0.6298\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 384s 8ms/step - loss: 1.0738 - acc: 0.6213 - val_loss: 1.0334 - val_acc: 0.6312\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 384s 8ms/step - loss: 1.0346 - acc: 0.6346 - val_loss: 0.9613 - val_acc: 0.6699\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.9972 - acc: 0.6476 - val_loss: 0.9266 - val_acc: 0.6805\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.9668 - acc: 0.6590 - val_loss: 0.8877 - val_acc: 0.6890\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 383s 8ms/step - loss: 0.9342 - acc: 0.6692 - val_loss: 0.8591 - val_acc: 0.6989\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 384s 8ms/step - loss: 0.9083 - acc: 0.6787 - val_loss: 0.8445 - val_acc: 0.7083\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.8818 - acc: 0.6897 - val_loss: 0.8329 - val_acc: 0.7076\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.8542 - acc: 0.6962 - val_loss: 0.8983 - val_acc: 0.6854\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.8337 - acc: 0.7059 - val_loss: 0.7812 - val_acc: 0.7290\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 383s 8ms/step - loss: 0.8094 - acc: 0.7149 - val_loss: 0.7867 - val_acc: 0.7284\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 383s 8ms/step - loss: 0.7867 - acc: 0.7215 - val_loss: 0.7637 - val_acc: 0.7369\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 382s 8ms/step - loss: 0.7665 - acc: 0.7311 - val_loss: 0.7540 - val_acc: 0.7400\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.7502 - acc: 0.7349 - val_loss: 0.7394 - val_acc: 0.7458\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.7310 - acc: 0.7422 - val_loss: 0.7146 - val_acc: 0.7523\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 381s 8ms/step - loss: 0.7176 - acc: 0.7483 - val_loss: 0.7132 - val_acc: 0.7535\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.6959 - acc: 0.7536 - val_loss: 0.7114 - val_acc: 0.7544\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 380s 8ms/step - loss: 0.6833 - acc: 0.7585 - val_loss: 0.6932 - val_acc: 0.7635\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 383s 8ms/step - loss: 0.6651 - acc: 0.7655 - val_loss: 0.6903 - val_acc: 0.7612\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 383s 8ms/step - loss: 0.6534 - acc: 0.7690 - val_loss: 0.7661 - val_acc: 0.7405\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 383s 8ms/step - loss: 0.6428 - acc: 0.7723 - val_loss: 0.6629 - val_acc: 0.7704\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 382s 8ms/step - loss: 0.6250 - acc: 0.7780 - val_loss: 0.6469 - val_acc: 0.7781\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    K.set_image_dim_ordering(\"th\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(IMG_DIM, (3, 3), padding='same', input_shape=X_train_nn.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(IMG_DIM, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(IMG_DIM * 2, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(IMG_DIM * 2, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(IMG_DIM * 16))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(NUM_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=PATIENCE)\n",
    "\n",
    "cnn = model.fit(X_train_nn, y_train_nn, validation_data=(X_test_nn, y_test_nn),\n",
    "               batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[early_stopping_monitor], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the validation accuracy over epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Validation Accuracy')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQURESmgoiAiIgX+H4mR+8CXbzrWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125a79748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(0)\n",
    "plt.plot(cnn.history['val_acc'],'g')\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(\"Validation Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best performing conventional classification machine learning algorithm, Random Forest, produced a mean test accuracy of 0.3588. Our conventional neural network algorithm produced a test accuracy score of 0.7781. This leads us to believe that using convolutional neural networks is the better choice for image recognition applications. It is noted that accuracy does not tell the whole story: taking a look at the classification score and the f1 scores for each class is important because it tells us how each class performs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
